{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Extraction and Classification from News Data (part 1)\n",
    "\n",
    "In this notebook we will introduce some tools to analyse the topics of a collection of news documents from the BBC.\n",
    "\n",
    "Here is the description of the dataset we will be using:\n",
    "\n",
    "http://mlg.ucd.ie/datasets/bbc.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "from pathlib import Path\n",
    "\n",
    "BBC_DATASET_URL = \"http://mlg.ucd.ie/files/datasets/bbc-fulltext.zip\"\n",
    "archive_filepath = Path(BBC_DATASET_URL.rsplit(\"/\", 1)[1])\n",
    "\n",
    "if not archive_filepath.exists():\n",
    "    print(f\"Downloading {BBC_DATASET_URL} to {archive_filepath}...\")\n",
    "    urlretrieve(BBC_DATASET_URL, archive_filepath)\n",
    "    print(\"done.\")\n",
    "else:\n",
    "    print(f\"{archive_filepath} exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "zf = ZipFile(archive_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zf.filelist[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zf.extractall(path=\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbc_folder_path = Path(\"bbc\")\n",
    "bbc_folder_path.is_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(bbc_folder_path.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((bbc_folder_path / \"README.TXT\").read_text(encoding=\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_filepaths = sorted(bbc_folder_path.glob(\"*/*.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_filepaths[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_filepaths[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(text_filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_filepath = text_filepaths[0]\n",
    "first_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(first_filepath.read_text(encoding=\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(first_filepath.read_text(encoding=\"iso-8859-1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in text_filepaths:\n",
    "    try:\n",
    "        path.read_text(encoding=\"utf-8\")\n",
    "    except Exception as e:\n",
    "        print(path)\n",
    "        print(type(e), e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b\"\\xa3\".decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b\"\\xa3\".decode(\"cp1252\")  # Western Europe (Windows code page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b\"\\xa3\".decode(\"cp1251\")  # Cyrillic (Windows code page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b\"\\xa3\".decode(\"cp932\")  # Japanese (Windows code page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b\"\\xa3\".decode(\"iso-8859-1\")  # also known as latin-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b\"\\xa3\".decode(\"iso-8859-15\")  # also known as latin-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problematic_filepath = Path(\"bbc/sport/199.txt\")\n",
    "print(problematic_filepath.read_text(encoding=\"iso-8859-1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(problematic_filepath.read_text(encoding=\"cp1251\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the context of an English speaking news site, a Western european code page makes more sense. However the first article is clearly utf-8 and the `bbc/sport/199.txt` article is clearly not utf-8.\n",
    "\n",
    "So it means that not all articles where encoded with the same encoding. The documentation of the dataset does not give us any information on which encoding was used.\n",
    "\n",
    "In this case we could try to guess, for instance using the `chardet.detect()` function to use a  machine learning model to guess the encoding of each document:\n",
    "\n",
    "https://pypi.org/project/chardet/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install chardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chardet\n",
    "\n",
    "chardet.detect(problematic_filepath.read_bytes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems to agree with our manual inspection of this file. However if we try chardet on the first document it gives a bad answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chardet.detect(first_filepath.read_bytes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we cannot trust this tool for this dataset. There is too much ambiguity. As we know that all documents are in English, most of the words should be represented the same way in both encodings. Let's just assume that UTF-8 was used everywhere and ignore/skip characters that cannot be decoded with the utf-8 encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(problematic_filepath.read_text(encoding=\"utf-8\", errors=\"ignore\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [path.read_text(encoding=\"utf-8\", errors=\"ignore\") for path in text_filepaths]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have loaded all the text documents in memory, we can load the target label (categories) of those documents by looking at the name of their parent folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_label_from_path(filepath):\n",
    "    return filepath.parent.name\n",
    "\n",
    "\n",
    "extract_label_from_path(first_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [extract_label_from_path(path) for path in text_filepaths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counter = Counter(categories)\n",
    "counter.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing Text Data: Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "count_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = \"C'est l'été au Brésil!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_analyzer = CountVectorizer().build_analyzer()\n",
    "word_analyzer(test_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_analyzer = CountVectorizer(strip_accents=\"unicode\", ngram_range=(2, 2)).build_analyzer()\n",
    "word_analyzer(test_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_analyzer = CountVectorizer(strip_accents=\"unicode\", ngram_range=(1, 2)).build_analyzer()\n",
    "word_analyzer(test_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_analyzer = CountVectorizer(ngram_range=(2, 2)).build_analyzer()\n",
    "word_analyzer(test_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_analyzer = CountVectorizer(analyzer=\"char\").build_analyzer()\n",
    "char_analyzer(test_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_analyzer = CountVectorizer(analyzer=\"char\", ngram_range=(1, 3)).build_analyzer()\n",
    "char_analyzer(test_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Text Classification Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Text Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of High Dimensional Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Similarity in a Low-rank Latent Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-3.7",
   "language": "python",
   "name": "python-3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
