{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Mining of BBC News Data\n",
    "\n",
    "## Part 3: Document Clustering in Reduced TF-IDF space\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "text_filepaths = sorted(Path(\"bbc\").glob(\"*/*.txt\"))\n",
    "categories = [p.parent.name for p in text_filepaths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    input=\"filename\", encoding=\"utf-8\", decode_error=\"ignore\",\n",
    "    min_df=5, max_df=0.7)\n",
    "\n",
    "tfidf_docs = tfidf_vectorizer.fit_transform(text_filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=5, n_init=1)\n",
    "kmeans_predictions = kmeans.fit_predict(tfidf_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.cluster_centers_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions**:\n",
    "\n",
    "- Run the previous clustering a second time, what do you observe?\n",
    "- Could you suggest why this is the case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_predictions[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "adjusted_rand_score(kmeans_predictions, categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_rand_score([0, 1, 1, 0], [\"a\", \"b\", \"b\", \"a\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_rand_score([2, 0, 0, 2], [\"a\", \"b\", \"b\", \"a\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_rand_score([1, 1, 0, 0], [\"a\", \"b\", \"b\", \"a\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_rand_score([1, 0, 0, 2], [\"a\", \"b\", \"b\", \"a\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some (supervised) clustering metrics:\n",
    "    \n",
    "- Adjusted Rand Index\n",
    "- Adjusted / Normalized Mutual Information\n",
    "- V-measure (homegeneity and completeness)\n",
    "\n",
    "When we don't have ground truth labels (which is most often the case, otherwise why not use a supervised classifier?), there is no single unique best way to quantify cluster quality/ One could use the following metrics but each of them makes different assumption on the question of what is a \"good\" clustering result:\n",
    "\n",
    "- Measure inter or intra cluster average / min / max distances.\n",
    "- Measure clustering stability when across resampling dataset and when adding small perturbations to the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercises**\n",
    "\n",
    "- Find the documentation of clustering metrics on the scikit-learn.org documentation;\n",
    "- What is the meaning of homogeneity and completeness;\n",
    "- On a toy dataset with only 4, and 2 \"true\" clustering classes, find a clustering that is homogeneous but not complete and the converse;\n",
    "- Compute the homogneity, completness and V-measure score for the results of the KMeans algorithm above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load notebook_solutions/homogeneity_vs_completeness.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Faster Clustering with Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "\n",
    "rp_kmeans = make_pipeline(GaussianRandomProjection(n_components=500),\n",
    "                          KMeans(n_clusters=5, n_init=10))\n",
    "rp_kmeans_predictions = rp_kmeans.fit_predict(tfidf_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_rand_score(rp_kmeans_predictions, categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions**:\n",
    "    \n",
    "- Try to reduce the dimension further, what do you observe?\n",
    "- What is the number of tunable parameters of the KMeans model in this case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd_kmeans = make_pipeline(TruncatedSVD(n_components=50),\n",
    "                           KMeans(n_clusters=5, n_init=10))\n",
    "svd_kmeans_predictions = svd_kmeans.fit_predict(tfidf_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_rand_score(svd_kmeans_predictions, categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**:\n",
    "\n",
    "- Compute the homogeneity and completeness scores for this pipeline;\n",
    "- Change the parameter `n_clusters`, how can you explain the results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**:\n",
    "\n",
    "- How text clustering can help datascientists?\n",
    "- What are some \"real word\" applications of unsupervised text clustering?\n",
    "- What is the main limitation of the use of clustering when trying to organize documents by topics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-3.7",
   "language": "python",
   "name": "python-3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
